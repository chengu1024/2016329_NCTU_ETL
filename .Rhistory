names(regionList)= regions
regionList[[1]]  = c(rep(1,35),0)
# 35 locations plus a constraint
# that the region effects sum to zero
for (j in 2:p) {
xj             = (CanadianWeather$region == regions.[j-1])
regionList[[j]]= c(xj,1)
}
# tempfd from chapter 9
Lcoef       = c(0,(2*pi/365)^2,0)
harmaccelLfd= vec2Lfd(Lcoef, c(0,365))
tempbasis   = create.fourier.basis(c(0, 365), 65)
lambda      = 1e6
tempfdPar65 = fdPar(tempbasis, harmaccelLfd, lambda)
tempShifted = daily$tempav[dayOfYearShifted, ]
tempSmooth65= smooth.basis(day.5, tempShifted, tempfdPar65)
tempfd      = tempSmooth65$fd
coef    = tempfd$coef
coef36  = cbind(coef,matrix(0,65,1))
temp36fd= fd(coef36,tempbasis,tempfd$fdnames)
betabasis      = create.fourier.basis(c(0, 365), 11)
betafdPar      = fdPar(betabasis)
betaList       = vector("list",p)
names(betaList)= regions
for (j in 1:p) betaList[[j]] = betafdPar
fRegressList= fRegress(temp36fd, regionList, betaList)
betaestList = fRegressList$betaestlist
regionFit   = fRegressList$yhatfd
# Figure 10.1
op          = par(mfrow=c(2,3),cex=1)
for (j in 1:p) plot(betaestList[[j]]$fd, lwd=2,
xlab="Day (July 1 to June 30)",
ylab="", main=regions[j])
plot(regionFit, lwd=2, col=1, lty=1,
xlab="Day (July 1 to June 30)", ylab="", main="Prediction")
par(op)
dayFine <- 1:365
beta.rgn <- lapply(betaestList[-1], predict, newdata=dayFine)
str(beta.rgn)
rgns <- ordered(regions., levels=regions.)
predTemp <- data.frame(day=dayFine,
region=rep(rgns, each=365),
beta.region=unlist(beta.rgn))
str(predTemp)
sapply(predTemp, length)
library(lattice)
xyplot(beta.region~day | region, predTemp, layout=c(4, 1), type='l')
xyplot(beta.region~day | region, predTemp, layout=c(4, 1), type='l',
scales=list(x=list(at=seq(1, 7, 2)*365/8,
labels=c("Q1", "Q2", "Q3", "Q4") )),
xlab='')
##
## Slide 8.  fRegress.fdPar: Concurrent Functional Model
##
# Section 10.2.3 Knee Angle Predicted from Hip Angle
gaittime = seq(0.5,19.5,1)
gaitrange = c(0,20)
gaitfine = seq(0,20,len=101)
harmaccelLfd20 = vec2Lfd(c(0, (2*pi/20)^2, 0), rangeval=gaitrange)
gaitbasis = create.fourier.basis(gaitrange, nbasis=21)
#    GCV is minimized with lambda = 10^(-1.5).
gaitSmooth = smooth.basisPar(gaittime, gait,
gaitbasis, Lfdobj=harmaccelLfd20, lambda=10^(-1.5))
gaitfd = gaitSmooth$fd
names(gaitfd$fdnames) = c("Normalized time", "Child", "Angle")
gaitfd$fdnames[[3]] = c("Hip", "Knee")
hipfd  = gaitfd[,1]
kneefd = gaitfd[,2]
kneefdMean = mean(kneefd)
xfdlist   = list(const=rep(1,39), hip=hipfd)
betafdPar = fdPar(gaitbasis, harmaccelLfd20)
betalist  = list(const=betafdPar, hip=betafdPar)
gaitRegress= fRegress(kneefd, xfdlist, betalist)
# Figure 10.7
harmaccelLfd365 <- vec2Lfd(c(0,(2*pi/365)^2,0), c(0, 365))
qqnorm(CanadianWeather$dailyAv[,,"Temperature.C"], datax=TRUE)
# Consistent with a strong annual cycle
# plus weaker normal noise
daytempfd <- with(CanadianWeather, smooth.basis(day.5,
dailyAv[,,"Temperature.C"],
daybasis65, fdnames=list("Day", "Station", "Deg C"))$fd )
plot(daytempfd, axes=FALSE)
axisIntervals(1)
axis(2)
# Check precipitation distribution
qqnorm(CanadianWeather$dailyAv[,,"Precipitation.mm"], datax=TRUE)
# Strongly lognormal?
quantile(CanadianWeather$dailyAv[,,"Precipitation.mm"])
# Can't take logarithms directly,
# because some observations are 0
sum(CanadianWeather$precav==0)
# 27 of 365
# Per help("CanadianWeather"),
sort(unique(diff(sort(unique(CanadianWeather$
dailyAv[,,"Precipitation.mm"])))))
# Some repeated numbers, indicating round off problems
sort(unique(diff(sort(round(unique(
CanadianWeather$dailyAv[,,"Precipitation.mm"]), 7)))))
sort(unique(round(diff(sort(round(unique(
CanadianWeather$dailyAv[,,"Precipitation.mm"]), 5) )),5)) )
# Obviously, the 0's are problems ... but ignore them
# The real point is that these numbers are all
# to the nearest tenth of a milimeter,
# & the 0 differences are created by anomolies in 'unique'
table(CanadianWeather$dailyAv[,,"Precipitation.mm"])
# help("CanadianWeather") says the 0's were replaced by 0.05 mm
# before computing logarithms
qqnorm(CanadianWeather$dailyAv[,,"log10precip"], datax=TRUE)
# Plausibly a weak annual cycle
# relative to substantial normal noise
# on a log scale
# Conclusion:  Prefer analysis on the log scale
# Back transform to get answers in 'mm' or approx. percent
# (recalling log(1+x) = x if x is small)
dayprecfd <- with(CanadianWeather, smooth.basis(day.5,
dailyAv[,,"log10precip"], daybasis65,
fdnames=list("Day", "Station", "log10(mm)"))$fd )
plot(dayprecfd, axes=FALSE)
axisIntervals(1)
axis(2)
# Or create a functional data object with Temp and log10precip together:
CanadianTempPrecip.fd <- with(CanadianWeather, smooth.basis(day.5,
dailyAv[,,-2], daybasis65)$fd )
str(CanadianTempPrecip.fd)
#  set up plotting arrangements for one and two panel displays allowing
#  for larger fonts
#  Plot temperature curves and values
# This plot would be too busy if we superimposed
# all 35 stations on the same page.
# Therefore, use "index" to make 5 separate plots
# Another alternative would be the 'ask' argument
# Returns invisibly the mean square deviations
# between observed and fdobj=daytempfd
(CanadianWea.MSE <- with(CanadianWeather, plotfit.fd(
y=dailyAv[,,"Temperature.C"], argvals=day.5,
fdobj=CanadianTempPrecip.fd[,1], index=1:7, axes=FALSE) ))
axisIntervals(1)
axis(2)
CanadianTempPrecip.fd <- with(CanadianWeather, smooth.basis(day.5,
dailyAv[,,-2], daybasis65)$fd )
daybasis65 <- create.fourier.basis(rangeval=c(0, 365), nbasis=65)
harmaccelLfd365 <- vec2Lfd(c(0,(2*pi/365)^2,0), c(0, 365))
qqnorm(CanadianWeather$dailyAv[,,"Temperature.C"], datax=TRUE)
# Consistent with a strong annual cycle
# plus weaker normal noise
daytempfd <- with(CanadianWeather, smooth.basis(day.5,
dailyAv[,,"Temperature.C"],
daybasis65, fdnames=list("Day", "Station", "Deg C"))$fd )
plot(daytempfd, axes=FALSE)
axisIntervals(1)
axis(2)
# Check precipitation distribution
qqnorm(CanadianWeather$dailyAv[,,"Precipitation.mm"], datax=TRUE)
# Strongly lognormal?
quantile(CanadianWeather$dailyAv[,,"Precipitation.mm"])
# Can't take logarithms directly,
# because some observations are 0
sum(CanadianWeather$precav==0)
# 27 of 365
# Per help("CanadianWeather"),
sort(unique(diff(sort(unique(CanadianWeather$
dailyAv[,,"Precipitation.mm"])))))
# Some repeated numbers, indicating round off problems
sort(unique(diff(sort(round(unique(
CanadianWeather$dailyAv[,,"Precipitation.mm"]), 7)))))
sort(unique(round(diff(sort(round(unique(
CanadianWeather$dailyAv[,,"Precipitation.mm"]), 5) )),5)) )
# Obviously, the 0's are problems ... but ignore them
# The real point is that these numbers are all
# to the nearest tenth of a milimeter,
# & the 0 differences are created by anomolies in 'unique'
table(CanadianWeather$dailyAv[,,"Precipitation.mm"])
# help("CanadianWeather") says the 0's were replaced by 0.05 mm
# before computing logarithms
qqnorm(CanadianWeather$dailyAv[,,"log10precip"], datax=TRUE)
# Plausibly a weak annual cycle
# relative to substantial normal noise
# on a log scale
# Conclusion:  Prefer analysis on the log scale
# Back transform to get answers in 'mm' or approx. percent
# (recalling log(1+x) = x if x is small)
dayprecfd <- with(CanadianWeather, smooth.basis(day.5,
dailyAv[,,"log10precip"], daybasis65,
fdnames=list("Day", "Station", "log10(mm)"))$fd )
plot(dayprecfd, axes=FALSE)
axisIntervals(1)
axis(2)
# Or create a functional data object with Temp and log10precip together:
CanadianTempPrecip.fd <- with(CanadianWeather, smooth.basis(day.5,
dailyAv[,,-2], daybasis65)$fd )
str(CanadianTempPrecip.fd)
#  set up plotting arrangements for one and two panel displays allowing
#  for larger fonts
#  Plot temperature curves and values
# This plot would be too busy if we superimposed
# all 35 stations on the same page.
# Therefore, use "index" to make 5 separate plots
# Another alternative would be the 'ask' argument
# Returns invisibly the mean square deviations
# between observed and fdobj=daytempfd
(CanadianWea.MSE <- with(CanadianWeather, plotfit.fd(
y=dailyAv[,,"Temperature.C"], argvals=day.5,
fdobj=CanadianTempPrecip.fd[,1], index=1:7, axes=FALSE) ))
axisIntervals(1)
axis(2)
with(CanadianWeather, plotfit.fd(y=dailyAv[,,"Temperature.C"],
argvals=day.5, fdobj=daytempfd, index=8:14, axes=FALSE) )
with(CanadianWeather, plotfit.fd(y=dailyAv[,,"Temperature.C"],
argvals=day.5, fdobj=daytempfd, index=22:28, axes=FALSE) )
# The smoothing is probably not quite adequate,
# but it's not bad either.
#  Plot residuals for three best fits and three worst fits
with(CanadianWeather, plotfit.fd(y=dailyAv[,,"Temperature.C"],
argvals=day.5, fdobj=daytempfd, index=c(1:3, 33:35),
nfine=366, residual=TRUE, sortwrd=TRUE, axes=FALSE) )
axes=FALSE) )
axisIntervals(1)
axis(2)
with(CanadianWeather, plotfit.fd(y=dailyAv[,,"log10precip"],
argvals=day.5, fdobj=dayprecfd, index=35, titles=place,
axes=FALSE) )
axisIntervals(1)
axis(2)
daytempfdSm <- smooth.fdPar(daytempfd, harmaccelLfd365, lambda=10)
dayprecfdSm <- smooth.fdPar(dayprecfd, harmaccelLfd365, lambda=1e5)
# Or
daytempSm <- smooth.fdPar(daytempfdSm, harmaccelLfd365, lambda=10)
str(daytempfdSm)
str(daytempSm)
# fdnames lost in bivariate ...
str(daytempfd)
#  Use function 'plotfit.fd' to plot the temperature data, fit and residuals
#    sorted by size of root mean square error
#  Plot temperature curves and values
with(CanadianWeather, plotfit.fd(y=dailyAv[,,"Temperature.C"],
argvals=day.5, fdobj=daytempSm, titles=place) )
with(CanadianWeather, plotfit.fd(dailyAv[,,"Temperature.C"],
day.5, daytempSm, index=c(1,2,3,33,34,35), sortwrd=TRUE,
residual=TRUE, titles=place, axes=FALSE) )
day.5, daytempSm, rng=c(0,31), titles=place) )
#  plot each pair of functions along with raw data
#par(mfrow=c(1,2), pty="s")
par(mfrow=c(2,1))
for (i in 1:length(CanadianWeather$place) ) {
with(CanadianWeather, plot(day.5, dailyAv[,i,"Temperature.C"],
type="p", xlim=c(0, 365), col=1, xlab="Day", ylab="",
main=paste(place[i],"temperature")) )
lines.fd(daytempSm[i])
with(CanadianWeather, plot(day.5, dailyAv[,i,"log10precip"],
type="p", xlim=c(0, 365), col=1, xlab="Day", ylab="",
main=paste(place[i],"precipitation")) )
lines.fd(dayprecfdSm[i])
# Uncomment the following line 'par(ask=TRUE)'
#  to plot the cuves one at a time
# Otherwise, they fly by faster than the eye can see.
par(ask=TRUE)
}
par(mfrow=c(1,1), pty="m", ask=FALSE)
#  plot all the functions
#par(mfrow=c(1,2), pty="s")
op <- par(mfrow=c(2,1))
plot(daytempfdSm, main="Temperature", axes=FALSE)
axisIntervals(1)
axis(2)
plot(dayprecfdSm, main="Precipitation", axes=FALSE)
axisIntervals(1)
axis(2)
par(op)
#  -------------------------------------------------------------
#                 Choose level of smoothing using
#          the generalized cross-validation criterion
#              with smoothing function smooth.basisPar.
#  -------------------------------------------------------------
wtvec <- rep(1,365)
# set up a saturated basis capable of interpolating the data
daybasis365 <- create.fourier.basis(c(0, 365), 365)
#  --------------------  smooth temperature  ------------------
#  set up range of smoothing parameters in log_10 units
?lines.fd
lines.fd(daytempSm[2])
install.packages(fda)
install.packages("fda")
install.packages("fda")
library(fda)
for (i in 1:length(CanadianWeather$place) ) {
with(CanadianWeather, plot(day.5, dailyAv[,i,"Temperature.C"],
type="p", xlim=c(0, 365), col=1, xlab="Day", ylab="",
main=paste(place[i],"temperature")) )
lines.fd(daytempSm[i])
with(CanadianWeather, plot(day.5, dailyAv[,i,"log10precip"],
type="p", xlim=c(0, 365), col=1, xlab="Day", ylab="",
main=paste(place[i],"precipitation")) )
lines(dayprecfdSm[i])
# Uncomment the following line 'par(ask=TRUE)'
#  to plot the cuves one at a time
# Otherwise, they fly by faster than the eye can see.
par(ask=TRUE)
}
for (i in 1:length(CanadianWeather$place) ) {
with(CanadianWeather, plot(day.5, dailyAv[,i,"Temperature.C"],
type="p", xlim=c(0, 365), col=1, xlab="Day", ylab="",
main=paste(place[i],"temperature")) )
lines(daytempSm[i])
with(CanadianWeather, plot(day.5, dailyAv[,i,"log10precip"],
type="p", xlim=c(0, 365), col=1, xlab="Day", ylab="",
main=paste(place[i],"precipitation")) )
lines(dayprecfdSm[i])
# Uncomment the following line 'par(ask=TRUE)'
#  to plot the cuves one at a time
# Otherwise, they fly by faster than the eye can see.
par(ask=TRUE)
}
setwd("/Users/Rafe/Dropbox/~OnGoing/2016329 NCTU_ETL/")
setwd("/Users/Rafe/Dropbox/~OnGoing/2016329 NCTU_ETL/")
ubike <- read.csv("./data/ubike-weather-utf8.csv",
colClasses = c("factor","integer","integer","factor","factor",
"numeric","numeric","integer","numeric","integer",
"integer","numeric","numeric", "integer","integer",
"numeric","numeric","numeric", "numeric","numeric",
"numeric", "numeric","numeric"), fileEncoding = 'utf8')
head(ublike)
head(ubike)
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
dcast(sna ~ is.rain, value.var="use_rate") %>%
arrange(desc(晴天)) %>% head(10) %>%
knitr::kable()
library(dplyr)
library(ggplot2)
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
dcast(sna ~ is.rain, value.var="use_rate") %>%
arrange(desc(晴天)) %>% head(10) %>%
knitr::kable()
library(reshape2)
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
dcast(sna ~ is.rain, value.var="use_rate") %>%
arrange(desc(晴天)) %>% head(10) %>%
knitr::kable()
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
dcast(sna ~ is.rain, value.var="use_rate") %>%
arrange(desc(晴天)) %>% head(10)
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F)
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna)) + geom_bar(aes(y = use_rate))
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna)) + geom_bar(aes(y = use_rate, stat = 'identity'))
ggplot(aes(x = sna, y = use_rate)) + geom_bar(aes(stat = 'identity'))
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate)) + geom_bar(aes(stat = 'identity'))
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate)) + geom_bar(stat = 'identity')
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate), group = sna, colour = is.rain) +
geom_bar(stat = 'identity')
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate), group = sna, color = is.rain) +
geom_bar(stat = 'identity')
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate, group = sna, color = is.rain)) +
geom_bar(stat = 'identity')
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate, group = sna, fill = is.rain)) +
geom_bar(stat = 'identity')
ls(pattern = '^geom_')
par(family = "STHeiti", mfrow = c(1,1))
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate, group = sna, fill = is.rain)) +
geom_bar(stat = 'identity')
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate, group = sna, fill = is.rain)) +
geom_bar(stat = 'identity') + theme_gray(base_family="STHeiti")
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate, group = sna, fill = is.rain)) +
geom_line(stat = 'identity') + theme_gray(base_family="STHeiti")
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate, group = sna, fill = is.rain)) +
geom_line()
ubike %>% filter(sarea == '信義區', hour == 8) %>%
mutate(is.rain = rainfall > 1) %>%
mutate(is.rain = factor(is.rain, levels=c(FALSE, TRUE),
labels = c("晴天","雨天"))) %>%
select(date, avg.bemp, sna, is.rain, tot) %>%
group_by(sna, is.rain) %>%
summarise(use_rate = mean(avg.bemp/tot, na.rm = TRUE)) %>%
filter(is.na(is.rain) == F) %>%
ggplot(aes(x = sna, y = use_rate, group = sna, fill = is.rain)) +
geom_point()
vignette(dplyr)
vignette('dplyr')
vignette(package='dplyr')
vignette(package='dplyr', topic = 'introduction')
vignette(package='reshape2')
vignette(package='ggplot2')
vignette(package='ggplot2', topic = 'ggplot2-specs')
